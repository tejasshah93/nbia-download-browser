-------------------------
title: Week 2  
date: 2015-06-10 14:30:00  
NOTES  
-------------------------

### Where does IndexedDB actually store data?
  http://www.aaron-powell.com/posts/2012-10-05-indexeddb-storage.html

### Last Week's Report:
  - Tar parsed completely using [node-tar](https://github.com/npm/node-tar)
  Resulted in generation of appropriate DICOM and annotation files. Just a
  minor encoding bug from last week resolved.
  - With keeping in mind as to storing the blobs in IndexedDB, explored and
  tried implementing various available libraries for file system API over
  IndexedDB as a wrapper, and thereafter parsing it by reading the stored tar
  from the DB.
  - Libraries referred:
  [IDBWrapper](http://jensarps.github.io/IDBWrapper/),
  [level-filesystem](https://github.com/mafintosh/level-filesystem),
  [level-browserify](https://github.com/Level/level-browserify),
  [tar-fs](https://github.com/mafintosh/tar-fs),
  [tar-stream](https://github.com/mafintosh/tar-stream)
  and allied alternatives..
  - Result: Sometimes modules not compatible with one another,
  levelDB utilizing much more space(~140MB for 20MB tar - redundant), need to
  drop level usage, browserify module explored for exporting functions to be
  used interactively in browser (instead of merely in bundle.js)

### Download Roadmap:
  In a sense, do we have to parse the tar stream after the whole tar of the
  series gets downloaded or as and when it comes (on the fly)?
    - The former one: Doable.Though doesn't ensure series download failure.
    - On the fly approach: Would work for resuming the series download.
      (Optimization part as mentioned in the proposal). Check the SOP ids and
      just send the rest from the server.
      *Problem*: Parse incomplete tar file? Error!
      Work around suggestion: Guess parser will return n-1 DICOM entries

### IndexedDB storage: What is and isn't required
  After the whole tar stream for a series gets downloaded, say we parse the tar
  stream and extract the files. What's the need to store the whole blob in
  IndexedDB? We can directly export the blob to client's file system. Though
  maintaining the series ID and corresponding SOP UIDs of DICOM files in
  IndexedDB for resuming failed downloads.
  - While exporting, the hierarchy of downloads needs to be discussed.

### NodeJS Modules in browser: http, stream, node-tar
  We *need* to use npm modules using browserify because if we download series
  using XHR instead, parsing the whole tar at once isn't feasible considering
  responsiveness of the browser. Instead something of the sorts
  `res.pipe(tar.Parse())` will be a preferred approach where res is the stream
  of response from the server directly piped to parser.

================================================================================
